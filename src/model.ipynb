{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2\n",
    "from config import *\n",
    "\n",
    "CATEGORIES_REV = {\n",
    "    0: 'alert', 1: 'button', 2: 'card', 3:'checkbox_checked',\n",
    "    4: 'checkbox_unchecked', 5: 'chip', 6: 'data_table', 7:'dropdown_menu',\n",
    "    8: 'floating_action_button', 9: 'grid_list', 10: 'image', 11: 'label', 12: 'menu',\n",
    "    13: 'radio_button_checked', 14: 'radio_button_unchecked', 15: 'slider', 16: 'switch_disabled',\n",
    "    17: 'switch_enabled', 18: 'text_area', 19: 'text_field', 20: 'tooltip'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a818fe93f1a5730"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class InputDate:\n",
    "    __slots__ = ['images', '__index', 'labels', '_size']\n",
    "    shape = (224, 224, 1)\n",
    "    \n",
    "    def __init__(self, _size: int) -> None:\n",
    "        self.images = np.empty((_size,) + self.shape, dtype='float16')\n",
    "        self.labels = np.empty(_size, dtype='uint8')\n",
    "        \n",
    "        self.__index = 0\n",
    "        self._size = _size\n",
    "    \n",
    "    def add_img(self, _path: str, _cat: int) -> None:\n",
    "        p = f\"data/train/{CATEGORIES_REV[_cat]}/{_path}\"\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.bitwise_not(img)\n",
    "        \n",
    "        self.images[self.__index] = \\\n",
    "            np.asarray(img).astype('float32').reshape(self.shape) / 255\n",
    "        self.labels[self.__index] = _cat\n",
    "        self.__index += 1\n",
    "        \n",
    "        if self.__index == self._size:\n",
    "            self.__done()\n",
    "            return\n",
    "            \n",
    "        print(f\"[+] Progress: {self.__index}/{self._size}\")\n",
    "    \n",
    "    def __done(self):\n",
    "        self.labels = to_categorical(self.labels)\n",
    "        print(f\"[+] DONE {self._size}/{self._size}\")\n",
    "    \n",
    "    def show(self, _i: int) -> None:\n",
    "        plt.imshow(self.images[_i], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "107fd48487f82e39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_input_f = pd.read_csv('data/processed/train_set.csv')\n",
    "\n",
    "td = InputDate(len(train_input_f))\n",
    "\n",
    "for i, _path, _cat in train_input_f.values:\n",
    "    td.add_img(_path, _cat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b90c8c5036cb556"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "td.show(14628)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18c10593983b89ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_input_f = pd.read_csv('data/processed/test_set.csv')\n",
    "\n",
    "test_d = InputDate(len(test_input_f))\n",
    "\n",
    "for i, _path, _cat in test_input_f.values:\n",
    "    test_d.add_img(_path, _cat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47950ba636dd6e8a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_d.show(345)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c265641e56914cef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "h_activ, f_activ = 'relu', 'softmax'\n",
    "kernel_s, pool_s = (3, 3), (2, 2)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_s, activation=h_activ, input_shape=td.shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=pool_s))\n",
    "model.add(layers.Conv2D(64, kernel_s, activation=h_activ))\n",
    "model.add(layers.MaxPooling2D(pool_size=pool_s))\n",
    "model.add(layers.Conv2D(64, kernel_s, activation=h_activ))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=h_activ))\n",
    "model.add(layers.Dense(COUNT, activation=f_activ))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(td.images, td.labels, epochs=COUNT, batch_size=64, validation_split=0.2)\n",
    "model.save('model_v0.1.h5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efd1878acf889169"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# \n",
    "# model_test = load_model('model_v0.1.h5')\n",
    "# \n",
    "# test_loss, test_acc = model_test.evaluate(test_d.images, test_d.labels)\n",
    "# print(f'Test accuracy: {test_acc}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "569633b89bed6778"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
